{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6. Triplet Loss.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "oLB18vxfxVRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "43091ada-19d2-4816-abf1-e0967e4b2b7a"
      },
      "cell_type": "code",
      "source": [
        "# we need to do this on colabatory because their version of keras that's installed is old\n",
        "!pip install keras --upgrade\n",
        "!pip install git+https://github.com/AI-Guru/ngdlm.git\n",
        "\n",
        "from keras import models, layers, optimizers\n",
        "from ngdlm import models as ngdlmodels\n",
        "from ngdlm import utils as ngdlmutils\n",
        "from keras.datasets import mnist\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.6)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Collecting git+https://github.com/AI-Guru/ngdlm.git\n",
            "  Cloning https://github.com/AI-Guru/ngdlm.git to /tmp/pip-req-build-asv1f7ab\n",
            "Requirement already satisfied (use --upgrade to upgrade): ngdlm==0.0.2rc1 from git+https://github.com/AI-Guru/ngdlm.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from ngdlm==0.0.2rc1) (2.2.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from ngdlm==0.0.2rc1) (1.12.0rc1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from ngdlm==0.0.2rc1) (2.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->ngdlm==0.0.2rc1) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->ngdlm==0.0.2rc1) (0.19.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->ngdlm==0.0.2rc1) (1.0.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->ngdlm==0.0.2rc1) (1.0.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->ngdlm==0.0.2rc1) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->ngdlm==0.0.2rc1) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->ngdlm==0.0.2rc1) (1.14.6)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ngdlm==0.0.2rc1) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ngdlm==0.0.2rc1) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ngdlm==0.0.2rc1) (3.6.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ngdlm==0.0.2rc1) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ngdlm==0.0.2rc1) (0.6.0)\n",
            "Requirement already satisfied: tensorboard<1.12.0,>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ngdlm==0.0.2rc1) (1.11.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ngdlm==0.0.2rc1) (0.32.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->ngdlm==0.0.2rc1) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ngdlm==0.0.2rc1) (2.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ngdlm==0.0.2rc1) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ngdlm==0.0.2rc1) (2.5.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib->ngdlm==0.0.2rc1) (2018.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow->ngdlm==0.0.2rc1) (40.4.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow->ngdlm==0.0.2rc1) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow->ngdlm==0.0.2rc1) (0.14.1)\n",
            "Building wheels for collected packages: ngdlm\n",
            "  Running setup.py bdist_wheel for ngdlm ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-svcp6ezf/wheels/93/06/27/e156acb49f475c364c3c9fa4ad4ab7bfa38808bff5bf9c4647\n",
            "Successfully built ngdlm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oGbA3lznxfLK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "2603d675-7a3e-4b87-e2fa-115cc260da59"
      },
      "cell_type": "code",
      "source": [
        "# this is the dimensionality of our latent space. We set it randomly to 8 to begin with\n",
        "latent_dim = 8\n",
        "\n",
        "# create a base model to begin\n",
        "# it's a little neural network that takes some input data and puts it into latent space, of size latent_dim\n",
        "base_input = layers.Input(shape=(28,28))\n",
        "base_output = base_input\n",
        "base_output = layers.Flatten()(base_output)\n",
        "base_output = layers.Dense(512,activation='relu')(base_output)\n",
        "base_output = layers.Dense(256,activation='relu')(base_output)\n",
        "base_output = layers.Dense(128,activation='relu')(base_output)\n",
        "base_output = layers.Dense(latent_dim)(base_output) # no activation means that it will be linear\n",
        "base = models.Model(base_input,base_output)\n",
        "base.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 28, 28)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 8)                 1032      \n",
            "=================================================================\n",
            "Total params: 567,176\n",
            "Trainable params: 567,176\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OrQXWyQCyRo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "657c7c30-1fac-4749-b254-458afca4e011"
      },
      "cell_type": "code",
      "source": [
        "# this now connects our base model to the 3 triplet loss models\n",
        "# we have three inputs (images), puts it into our base model, and then outputs into a concatenated latent space\n",
        "tl = ngdlmodels.TL(base)\n",
        "tl.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Basemodel:\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 28, 28)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 8)                 1032      \n",
            "=================================================================\n",
            "Total params: 567,176\n",
            "Trainable params: 567,176\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Siamese model:\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 28, 28)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 28, 28)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            (None, 28, 28)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Model)                 (None, 8)            567176      input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "                                                                 input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 24)           0           model_2[1][0]                    \n",
            "                                                                 model_2[2][0]                    \n",
            "                                                                 model_2[3][0]                    \n",
            "==================================================================================================\n",
            "Total params: 567,176\n",
            "Trainable params: 567,176\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yp73ogUryyiU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# now we can compile the model\n",
        "tl.compile(\n",
        "    optimizer = 'rmsprop',\n",
        "    triplet_loss = 'euclidean' # this is just straight distances between points in latent space (cosine distance is an alternative) \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bTwJ8aMSztaI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load some data for our model\n",
        "(x_input_train,y_output_train),(x_input_test,y_output_test) = mnist.load_data()\n",
        "x_input_train = x_input_train.astype('float32') / 255.0\n",
        "x_input_test = x_input_test.astype('float32') / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3QhwqDa10Evl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 19135
        },
        "outputId": "cea1e326-2126-4d34-e73e-fcaa0f896964"
      },
      "cell_type": "code",
      "source": [
        "# now we fit our model on mnist training data\n",
        "history = tl.fit(\n",
        "    x_input_train,y_output_train,\n",
        "    epochs = 1000,\n",
        "    batch_size = 128,\n",
        "    steps_per_epoch = 1000,\n",
        "    minibatch_size = 10,\n",
        "    shuffle = True,\n",
        "    validation_data = (x_input_test,y_output_test),\n",
        "    validation_steps = 500\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000...\n",
            "loss [0.0016720831571146845]\n",
            "val_loss [0.23433858156204224]\n",
            "Epoch 2/1000...\n",
            "loss [0.002009627615334466]\n",
            "val_loss [0.33618417382240295]\n",
            "Epoch 3/1000...\n",
            "loss [0.001660420143045485]\n",
            "val_loss [0.3056345582008362]\n",
            "Epoch 4/1000...\n",
            "loss [0.001547861116239801]\n",
            "val_loss [0.37241530418395996]\n",
            "Epoch 5/1000...\n",
            "loss [0.0016469977933447808]\n",
            "val_loss [0.3387838304042816]\n",
            "Epoch 6/1000...\n",
            "loss [0.0013707638517953455]\n",
            "val_loss [0.43914666771888733]\n",
            "Epoch 7/1000...\n",
            "loss [0.0016662691016681493]\n",
            "val_loss [0.2714526951313019]\n",
            "Epoch 8/1000...\n",
            "loss [0.0013302800415549427]\n",
            "val_loss [0.3056591749191284]\n",
            "Epoch 9/1000...\n",
            "loss [0.0012442319870460778]\n",
            "val_loss [0.3001728653907776]\n",
            "Epoch 10/1000...\n",
            "loss [0.0011684680886100978]\n",
            "val_loss [0.49239349365234375]\n",
            "Epoch 11/1000...\n",
            "loss [0.0012558576432056725]\n",
            "val_loss [0.26396065950393677]\n",
            "Epoch 12/1000...\n",
            "loss [0.001152068650117144]\n",
            "val_loss [0.30153581500053406]\n",
            "Epoch 13/1000...\n",
            "loss [0.0010593898063525557]\n",
            "val_loss [0.2183527797460556]\n",
            "Epoch 14/1000...\n",
            "loss [0.0011894326000474393]\n",
            "val_loss [0.3324887156486511]\n",
            "Epoch 15/1000...\n",
            "loss [0.001093866112176329]\n",
            "val_loss [0.17015588283538818]\n",
            "Epoch 16/1000...\n",
            "loss [0.000927862505428493]\n",
            "val_loss [0.29406437277793884]\n",
            "Epoch 17/1000...\n",
            "loss [0.0008944591064937412]\n",
            "val_loss [0.3328394591808319]\n",
            "Epoch 18/1000...\n",
            "loss [0.0011241122516803443]\n",
            "val_loss [0.3333496153354645]\n",
            "Epoch 19/1000...\n",
            "loss [0.0010217120277229697]\n",
            "val_loss [0.30406665802001953]\n",
            "Epoch 20/1000...\n",
            "loss [0.0010063581797294318]\n",
            "val_loss [0.23947690427303314]\n",
            "Epoch 21/1000...\n",
            "loss [0.0008798809144645929]\n",
            "val_loss [0.23783181607723236]\n",
            "Epoch 22/1000...\n",
            "loss [0.0007700415302533656]\n",
            "val_loss [0.3004728853702545]\n",
            "Epoch 23/1000...\n",
            "loss [0.0007991743739694356]\n",
            "val_loss [0.2905305325984955]\n",
            "Epoch 24/1000...\n",
            "loss [0.0008010779921896756]\n",
            "val_loss [0.2168285995721817]\n",
            "Epoch 25/1000...\n",
            "loss [0.0006307862580288201]\n",
            "val_loss [0.24423068761825562]\n",
            "Epoch 26/1000...\n",
            "loss [0.000705352170392871]\n",
            "val_loss [0.31835997104644775]\n",
            "Epoch 27/1000...\n",
            "loss [0.0006367371077649295]\n",
            "val_loss [0.19271999597549438]\n",
            "Epoch 28/1000...\n",
            "loss [0.0005349596301093697]\n",
            "val_loss [0.27675172686576843]\n",
            "Epoch 29/1000...\n",
            "loss [0.0005499435642268509]\n",
            "val_loss [0.31886404752731323]\n",
            "Epoch 30/1000...\n",
            "loss [0.0007323024689685553]\n",
            "val_loss [0.23767343163490295]\n",
            "Epoch 31/1000...\n",
            "loss [0.0004917701706290245]\n",
            "val_loss [0.29025524854660034]\n",
            "Epoch 32/1000...\n",
            "loss [0.0006410505631938576]\n",
            "val_loss [0.18978622555732727]\n",
            "Epoch 33/1000...\n",
            "loss [0.0006856982572935521]\n",
            "val_loss [0.22680269181728363]\n",
            "Epoch 34/1000...\n",
            "loss [0.0005219670238438993]\n",
            "val_loss [0.19998399913311005]\n",
            "Epoch 35/1000...\n",
            "loss [0.0006011569197289646]\n",
            "val_loss [0.2550150752067566]\n",
            "Epoch 36/1000...\n",
            "loss [0.0006278934543952346]\n",
            "val_loss [0.22348664700984955]\n",
            "Epoch 37/1000...\n",
            "loss [0.0004615241556894034]\n",
            "val_loss [0.15138736367225647]\n",
            "Epoch 38/1000...\n",
            "loss [0.00047847888991236684]\n",
            "val_loss [0.2481742799282074]\n",
            "Epoch 39/1000...\n",
            "loss [0.0006024818364530802]\n",
            "val_loss [0.23457317054271698]\n",
            "Epoch 40/1000...\n",
            "loss [0.0005392380026169122]\n",
            "val_loss [0.3097025156021118]\n",
            "Epoch 41/1000...\n",
            "loss [0.0004951369995251298]\n",
            "val_loss [0.24550233781337738]\n",
            "Epoch 42/1000...\n",
            "loss [0.0004300897323992103]\n",
            "val_loss [0.2713530659675598]\n",
            "Epoch 43/1000...\n",
            "loss [0.000642349035711959]\n",
            "val_loss [0.2236616313457489]\n",
            "Epoch 44/1000...\n",
            "loss [0.000533971288939938]\n",
            "val_loss [0.1645517647266388]\n",
            "Epoch 45/1000...\n",
            "loss [0.00037201571161858736]\n",
            "val_loss [0.1878061592578888]\n",
            "Epoch 46/1000...\n",
            "loss [0.0004766354362946004]\n",
            "val_loss [0.22284531593322754]\n",
            "Epoch 47/1000...\n",
            "loss [0.0004939292799681425]\n",
            "val_loss [0.13702431321144104]\n",
            "Epoch 48/1000...\n",
            "loss [0.0004000976320821792]\n",
            "val_loss [0.2590998411178589]\n",
            "Epoch 49/1000...\n",
            "loss [0.0005265315342694521]\n",
            "val_loss [0.1839543879032135]\n",
            "Epoch 50/1000...\n",
            "loss [0.00040912607288919387]\n",
            "val_loss [0.21167263388633728]\n",
            "Epoch 51/1000...\n",
            "loss [0.0004127878665458411]\n",
            "val_loss [0.258073091506958]\n",
            "Epoch 52/1000...\n",
            "loss [0.00038130126520991324]\n",
            "val_loss [0.20822453498840332]\n",
            "Epoch 53/1000...\n",
            "loss [0.0005440867128781974]\n",
            "val_loss [0.15195244550704956]\n",
            "Epoch 54/1000...\n",
            "loss [0.0003312688486184925]\n",
            "val_loss [0.24807330965995789]\n",
            "Epoch 55/1000...\n",
            "loss [0.0003905360281933099]\n",
            "val_loss [0.20680156350135803]\n",
            "Epoch 56/1000...\n",
            "loss [0.0004873043157858774]\n",
            "val_loss [0.22388586401939392]\n",
            "Epoch 57/1000...\n",
            "loss [0.00047657288273330776]\n",
            "val_loss [0.12133999168872833]\n",
            "Epoch 58/1000...\n",
            "loss [0.00042514823866076766]\n",
            "val_loss [0.17404097318649292]\n",
            "Epoch 59/1000...\n",
            "loss [0.0003606463067699224]\n",
            "val_loss [0.23719368875026703]\n",
            "Epoch 60/1000...\n",
            "loss [0.0004135914035141468]\n",
            "val_loss [0.31400084495544434]\n",
            "Epoch 61/1000...\n",
            "loss [0.00036667779786512254]\n",
            "val_loss [0.11090162396430969]\n",
            "Epoch 62/1000...\n",
            "loss [0.0004087871871888638]\n",
            "val_loss [0.19365651905536652]\n",
            "Epoch 63/1000...\n",
            "loss [0.00036821302073076367]\n",
            "val_loss [0.22870755195617676]\n",
            "Epoch 64/1000...\n",
            "loss [0.00029062048648484054]\n",
            "val_loss [0.24715034663677216]\n",
            "Epoch 65/1000...\n",
            "loss [0.00046964115090668203]\n",
            "val_loss [0.20919279754161835]\n",
            "Epoch 66/1000...\n",
            "loss [0.0003192076776176691]\n",
            "val_loss [0.28705957531929016]\n",
            "Epoch 67/1000...\n",
            "loss [0.000356902448926121]\n",
            "val_loss [0.2429949939250946]\n",
            "Epoch 68/1000...\n",
            "loss [0.00034254076331853865]\n",
            "val_loss [0.20664376020431519]\n",
            "Epoch 69/1000...\n",
            "loss [0.00036248865048401057]\n",
            "val_loss [0.226045161485672]\n",
            "Epoch 70/1000...\n",
            "loss [0.00033004415431059895]\n",
            "val_loss [0.20580913126468658]\n",
            "Epoch 71/1000...\n",
            "loss [0.00035373271722346545]\n",
            "val_loss [0.17375710606575012]\n",
            "Epoch 72/1000...\n",
            "loss [0.00034373694844543935]\n",
            "val_loss [0.09046551585197449]\n",
            "Epoch 73/1000...\n",
            "loss [0.00036196462996304033]\n",
            "val_loss [0.19279441237449646]\n",
            "Epoch 74/1000...\n",
            "loss [0.00026748896413482723]\n",
            "val_loss [0.14187484979629517]\n",
            "Epoch 75/1000...\n",
            "loss [0.0005083187818527222]\n",
            "val_loss [0.22501027584075928]\n",
            "Epoch 76/1000...\n",
            "loss [0.00029218682460486887]\n",
            "val_loss [0.22560474276542664]\n",
            "Epoch 77/1000...\n",
            "loss [0.00039927287492901086]\n",
            "val_loss [0.16398778557777405]\n",
            "Epoch 78/1000...\n",
            "loss [0.00041961475694552065]\n",
            "val_loss [0.17090454697608948]\n",
            "Epoch 79/1000...\n",
            "loss [0.0002292089369148016]\n",
            "val_loss [0.22878241539001465]\n",
            "Epoch 80/1000...\n",
            "loss [0.00044202142488211394]\n",
            "val_loss [0.16387540102005005]\n",
            "Epoch 81/1000...\n",
            "loss [0.0002945242365822196]\n",
            "val_loss [0.21430599689483643]\n",
            "Epoch 82/1000...\n",
            "loss [0.00027303987182676794]\n",
            "val_loss [0.26063621044158936]\n",
            "Epoch 83/1000...\n",
            "loss [0.0003659845031797886]\n",
            "val_loss [0.18068283796310425]\n",
            "Epoch 84/1000...\n",
            "loss [0.00024933703476563094]\n",
            "val_loss [0.29130759835243225]\n",
            "Epoch 85/1000...\n",
            "loss [0.00033551052515394986]\n",
            "val_loss [0.21813660860061646]\n",
            "Epoch 86/1000...\n",
            "loss [0.00023692975426092743]\n",
            "val_loss [0.1794312447309494]\n",
            "Epoch 87/1000...\n",
            "loss [0.00025354958768002687]\n",
            "val_loss [0.24359211325645447]\n",
            "Epoch 88/1000...\n",
            "loss [0.00034803191386163237]\n",
            "val_loss [0.1228657066822052]\n",
            "Epoch 89/1000...\n",
            "loss [0.0002115056999027729]\n",
            "val_loss [0.19581907987594604]\n",
            "Epoch 90/1000...\n",
            "loss [0.0002776889658998698]\n",
            "val_loss [0.1444203108549118]\n",
            "Epoch 91/1000...\n",
            "loss [0.0002701712150592357]\n",
            "val_loss [0.19278687238693237]\n",
            "Epoch 92/1000...\n",
            "loss [0.00015750205353833735]\n",
            "val_loss [0.15559890866279602]\n",
            "Epoch 93/1000...\n",
            "loss [0.0002262944767717272]\n",
            "val_loss [0.17846879363059998]\n",
            "Epoch 94/1000...\n",
            "loss [0.0002547031808644533]\n",
            "val_loss [0.10999291390180588]\n",
            "Epoch 95/1000...\n",
            "loss [0.00025745217967778445]\n",
            "val_loss [0.11284658312797546]\n",
            "Epoch 96/1000...\n",
            "loss [0.0002736322325654328]\n",
            "val_loss [0.11605125665664673]\n",
            "Epoch 97/1000...\n",
            "loss [0.00018407696415670215]\n",
            "val_loss [0.14196079969406128]\n",
            "Epoch 98/1000...\n",
            "loss [0.0003419745182618499]\n",
            "val_loss [0.11789827048778534]\n",
            "Epoch 99/1000...\n",
            "loss [0.00022871485352516174]\n",
            "val_loss [0.16781625151634216]\n",
            "Epoch 100/1000...\n",
            "loss [0.00034280683007091285]\n",
            "val_loss [0.2329181730747223]\n",
            "Epoch 101/1000...\n",
            "loss [0.00029529114812612534]\n",
            "val_loss [0.18759819865226746]\n",
            "Epoch 102/1000...\n",
            "loss [0.00028813980147242546]\n",
            "val_loss [0.14465603232383728]\n",
            "Epoch 103/1000...\n",
            "loss [0.00028780062031000855]\n",
            "val_loss [0.24504326283931732]\n",
            "Epoch 104/1000...\n",
            "loss [0.00018723760545253753]\n",
            "val_loss [0.20355011522769928]\n",
            "Epoch 105/1000...\n",
            "loss [0.0002614230797626078]\n",
            "val_loss [0.1325720250606537]\n",
            "Epoch 106/1000...\n",
            "loss [0.00020973456045612692]\n",
            "val_loss [0.12855413556098938]\n",
            "Epoch 107/1000...\n",
            "loss [0.0003057190913241357]\n",
            "val_loss [0.1422819197177887]\n",
            "Epoch 108/1000...\n",
            "loss [0.00022340470412746073]\n",
            "val_loss [0.1412947177886963]\n",
            "Epoch 109/1000...\n",
            "loss [0.00021239867247641086]\n",
            "val_loss [0.17130781710147858]\n",
            "Epoch 110/1000...\n",
            "loss [0.00020012615947052838]\n",
            "val_loss [0.14335153996944427]\n",
            "Epoch 111/1000...\n",
            "loss [0.00027572284685447814]\n",
            "val_loss [0.16952717304229736]\n",
            "Epoch 112/1000...\n",
            "loss [0.00031942815170623364]\n",
            "val_loss [0.131972536444664]\n",
            "Epoch 113/1000...\n",
            "loss [0.0002582148888614029]\n",
            "val_loss [0.2028982937335968]\n",
            "Epoch 114/1000...\n",
            "loss [0.00018569529592059553]\n",
            "val_loss [0.09420257806777954]\n",
            "Epoch 115/1000...\n",
            "loss [0.0002943835980258882]\n",
            "val_loss [0.18193255364894867]\n",
            "Epoch 116/1000...\n",
            "loss [0.00024891651165671647]\n",
            "val_loss [0.14512309432029724]\n",
            "Epoch 117/1000...\n",
            "loss [0.0002981781717389822]\n",
            "val_loss [0.1095636785030365]\n",
            "Epoch 118/1000...\n",
            "loss [0.00022296382999047637]\n",
            "val_loss [0.13839678466320038]\n",
            "Epoch 119/1000...\n",
            "loss [0.00016974583617411553]\n",
            "val_loss [0.16265837848186493]\n",
            "Epoch 120/1000...\n",
            "loss [0.00022438173182308673]\n",
            "val_loss [0.18661172688007355]\n",
            "Epoch 121/1000...\n",
            "loss [0.0002509002371225506]\n",
            "val_loss [0.13087929785251617]\n",
            "Epoch 122/1000...\n",
            "loss [0.0003224629210308194]\n",
            "val_loss [0.1575704962015152]\n",
            "Epoch 123/1000...\n",
            "loss [0.0002398379340302199]\n",
            "val_loss [0.12493281066417694]\n",
            "Epoch 124/1000...\n",
            "loss [0.0002203000346198678]\n",
            "val_loss [0.1464664191007614]\n",
            "Epoch 125/1000...\n",
            "loss [0.00025383232813328503]\n",
            "val_loss [0.1462923139333725]\n",
            "Epoch 126/1000...\n",
            "loss [0.00023752233479171992]\n",
            "val_loss [0.18931818008422852]\n",
            "Epoch 127/1000...\n",
            "loss [0.00023997909529134632]\n",
            "val_loss [0.21190467476844788]\n",
            "Epoch 128/1000...\n",
            "loss [0.0001370254149660468]\n",
            "val_loss [0.2294684499502182]\n",
            "Epoch 129/1000...\n",
            "loss [0.0002973355134017766]\n",
            "val_loss [0.20150500535964966]\n",
            "Epoch 130/1000...\n",
            "loss [0.00014023272693157197]\n",
            "val_loss [0.14320671558380127]\n",
            "Epoch 131/1000...\n",
            "loss [0.0002845677507575601]\n",
            "val_loss [0.11259351670742035]\n",
            "Epoch 132/1000...\n",
            "loss [0.00024864450399763883]\n",
            "val_loss [0.11667262017726898]\n",
            "Epoch 133/1000...\n",
            "loss [0.0001699164139572531]\n",
            "val_loss [0.1604556292295456]\n",
            "Epoch 134/1000...\n",
            "loss [0.00020579533674754203]\n",
            "val_loss [0.1145811378955841]\n",
            "Epoch 135/1000...\n",
            "loss [0.0001908116224221885]\n",
            "val_loss [0.11957580596208572]\n",
            "Epoch 136/1000...\n",
            "loss [0.0002175841210409999]\n",
            "val_loss [0.150184765458107]\n",
            "Epoch 137/1000...\n",
            "loss [0.00017987305973656475]\n",
            "val_loss [0.17032819986343384]\n",
            "Epoch 138/1000...\n",
            "loss [0.0002463105346541852]\n",
            "val_loss [0.1922847330570221]\n",
            "Epoch 139/1000...\n",
            "loss [0.00019123675860464572]\n",
            "val_loss [0.22500434517860413]\n",
            "Epoch 140/1000...\n",
            "loss [0.00019671382196247578]\n",
            "val_loss [0.1556386947631836]\n",
            "Epoch 141/1000...\n",
            "loss [0.0002576333989854902]\n",
            "val_loss [0.125700443983078]\n",
            "Epoch 142/1000...\n",
            "loss [0.00016097090812399983]\n",
            "val_loss [0.09052659571170807]\n",
            "Epoch 143/1000...\n",
            "loss [0.00028086198680102824]\n",
            "val_loss [0.22891384363174438]\n",
            "Epoch 144/1000...\n",
            "loss [0.00023859901959076525]\n",
            "val_loss [0.1212296187877655]\n",
            "Epoch 145/1000...\n",
            "loss [0.00019128678273409606]\n",
            "val_loss [0.17876236140727997]\n",
            "Epoch 146/1000...\n",
            "loss [0.00020691021461971104]\n",
            "val_loss [0.12496139109134674]\n",
            "Epoch 147/1000...\n",
            "loss [0.00019194409344345332]\n",
            "val_loss [0.1684839129447937]\n",
            "Epoch 148/1000...\n",
            "loss [0.0001771972116548568]\n",
            "val_loss [0.1722184270620346]\n",
            "Epoch 149/1000...\n",
            "loss [0.0002199817292857915]\n",
            "val_loss [0.14026743173599243]\n",
            "Epoch 150/1000...\n",
            "loss [0.00013947899686172604]\n",
            "val_loss [0.1751769483089447]\n",
            "Epoch 151/1000...\n",
            "loss [0.0002720405985601246]\n",
            "val_loss [0.16488845646381378]\n",
            "Epoch 152/1000...\n",
            "loss [0.00025251867342740295]\n",
            "val_loss [0.12717972695827484]\n",
            "Epoch 153/1000...\n",
            "loss [0.00013970032893121243]\n",
            "val_loss [0.15193921327590942]\n",
            "Epoch 154/1000...\n",
            "loss [0.000210627774707973]\n",
            "val_loss [0.134546160697937]\n",
            "Epoch 155/1000...\n",
            "loss [0.00018024018965661525]\n",
            "val_loss [0.13311833143234253]\n",
            "Epoch 156/1000...\n",
            "loss [0.00022435903223231435]\n",
            "val_loss [0.14191834628582]\n",
            "Epoch 157/1000...\n",
            "loss [0.00023327138647437096]\n",
            "val_loss [0.12413454800844193]\n",
            "Epoch 158/1000...\n",
            "loss [0.00013087733369320631]\n",
            "val_loss [0.11829137802124023]\n",
            "Epoch 159/1000...\n",
            "loss [0.00023665396240539848]\n",
            "val_loss [0.13867294788360596]\n",
            "Epoch 160/1000...\n",
            "loss [0.00015235747955739498]\n",
            "val_loss [0.1087530106306076]\n",
            "Epoch 161/1000...\n",
            "loss [0.00022270308062434196]\n",
            "val_loss [0.13852091133594513]\n",
            "Epoch 162/1000...\n",
            "loss [0.00016451379284262657]\n",
            "val_loss [0.14965887367725372]\n",
            "Epoch 163/1000...\n",
            "loss [0.0002354513416066766]\n",
            "val_loss [0.12187151610851288]\n",
            "Epoch 164/1000...\n",
            "loss [0.00013150401040911674]\n",
            "val_loss [0.11203354597091675]\n",
            "Epoch 165/1000...\n",
            "loss [0.0001617770455777645]\n",
            "val_loss [0.19411610066890717]\n",
            "Epoch 166/1000...\n",
            "loss [0.00014155000634491445]\n",
            "val_loss [0.1746629923582077]\n",
            "Epoch 167/1000...\n",
            "loss [0.0002397057011257857]\n",
            "val_loss [0.11927823722362518]\n",
            "Epoch 168/1000...\n",
            "loss [0.0001734682759270072]\n",
            "val_loss [0.2509733736515045]\n",
            "Epoch 169/1000...\n",
            "loss [0.0002694535437040031]\n",
            "val_loss [0.07176721841096878]\n",
            "Epoch 170/1000...\n",
            "loss [0.00023453095369040965]\n",
            "val_loss [0.20001912117004395]\n",
            "Epoch 171/1000...\n",
            "loss [0.0002495068199932575]\n",
            "val_loss [0.13347601890563965]\n",
            "Epoch 172/1000...\n",
            "loss [0.00019475807994604111]\n",
            "val_loss [0.15833315253257751]\n",
            "Epoch 173/1000...\n",
            "loss [0.00016488603316247463]\n",
            "val_loss [0.15167975425720215]\n",
            "Epoch 174/1000...\n",
            "loss [0.0001812635150272399]\n",
            "val_loss [0.17241564393043518]\n",
            "Epoch 175/1000...\n",
            "loss [0.0001830006807576865]\n",
            "val_loss [0.12657809257507324]\n",
            "Epoch 176/1000...\n",
            "loss [0.0001791213674005121]\n",
            "val_loss [0.14866496622562408]\n",
            "Epoch 177/1000...\n",
            "loss [0.00022731741797178985]\n",
            "val_loss [0.11068205535411835]\n",
            "Epoch 178/1000...\n",
            "loss [0.00017111999401822687]\n",
            "val_loss [0.13749250769615173]\n",
            "Epoch 179/1000...\n",
            "loss [0.00012134173302911223]\n",
            "val_loss [0.18868482112884521]\n",
            "Epoch 180/1000...\n",
            "loss [0.00012739481520839034]\n",
            "val_loss [0.108883336186409]\n",
            "Epoch 181/1000...\n",
            "loss [0.0001248767387587577]\n",
            "val_loss [0.17792931199073792]\n",
            "Epoch 182/1000...\n",
            "loss [0.00020881807478144765]\n",
            "val_loss [0.11182058602571487]\n",
            "Epoch 183/1000...\n",
            "loss [0.00018844346120022238]\n",
            "val_loss [0.22703132033348083]\n",
            "Epoch 184/1000...\n",
            "loss [0.0001891496847383678]\n",
            "val_loss [0.14339657127857208]\n",
            "Epoch 185/1000...\n",
            "loss [0.00020241625234484673]\n",
            "val_loss [0.18314823508262634]\n",
            "Epoch 186/1000...\n",
            "loss [0.00018148076441138982]\n",
            "val_loss [0.12140817940235138]\n",
            "Epoch 187/1000...\n",
            "loss [0.0002623716390226036]\n",
            "val_loss [0.11494015157222748]\n",
            "Epoch 188/1000...\n",
            "loss [0.00018696494959294797]\n",
            "val_loss [0.21966597437858582]\n",
            "Epoch 189/1000...\n",
            "loss [0.00028054135874845085]\n",
            "val_loss [0.1696387380361557]\n",
            "Epoch 190/1000...\n",
            "loss [0.00014880212768912315]\n",
            "val_loss [0.09137673676013947]\n",
            "Epoch 191/1000...\n",
            "loss [0.00017774037853814662]\n",
            "val_loss [0.09135127812623978]\n",
            "Epoch 192/1000...\n",
            "loss [0.000258176525356248]\n",
            "val_loss [0.13594718277454376]\n",
            "Epoch 193/1000...\n",
            "loss [0.00019226614804938435]\n",
            "val_loss [0.08493100106716156]\n",
            "Epoch 194/1000...\n",
            "loss [0.00019353949069045485]\n",
            "val_loss [0.0950404554605484]\n",
            "Epoch 195/1000...\n",
            "loss [0.00011651104781776667]\n",
            "val_loss [0.09968309104442596]\n",
            "Epoch 196/1000...\n",
            "loss [0.00022041179053485394]\n",
            "val_loss [0.13994765281677246]\n",
            "Epoch 197/1000...\n",
            "loss [0.00025358804152347147]\n",
            "val_loss [0.1677723526954651]\n",
            "Epoch 198/1000...\n",
            "loss [0.00013689911481924355]\n",
            "val_loss [0.22230416536331177]\n",
            "Epoch 199/1000...\n",
            "loss [0.00022544481605291366]\n",
            "val_loss [0.13251993060112]\n",
            "Epoch 200/1000...\n",
            "loss [0.0002146017481572926]\n",
            "val_loss [0.13163860142230988]\n",
            "Epoch 201/1000...\n",
            "loss [0.00010182620631530881]\n",
            "val_loss [0.14564839005470276]\n",
            "Epoch 202/1000...\n",
            "loss [0.00016231796494685114]\n",
            "val_loss [0.14574596285820007]\n",
            "Epoch 203/1000...\n",
            "loss [0.00013419936504215]\n",
            "val_loss [0.0954819917678833]\n",
            "Epoch 204/1000...\n",
            "loss [0.00015555165428668262]\n",
            "val_loss [0.19612087309360504]\n",
            "Epoch 205/1000...\n",
            "loss [0.00011384619027376175]\n",
            "val_loss [0.07168971747159958]\n",
            "Epoch 206/1000...\n",
            "loss [0.0001626806790009141]\n",
            "val_loss [0.09928594529628754]\n",
            "Epoch 207/1000...\n",
            "loss [0.00019108528085052967]\n",
            "val_loss [0.130326509475708]\n",
            "Epoch 208/1000...\n",
            "loss [0.00016495568491518497]\n",
            "val_loss [0.23044826090335846]\n",
            "Epoch 209/1000...\n",
            "loss [0.00012404131842777132]\n",
            "val_loss [0.1601223647594452]\n",
            "Epoch 210/1000...\n",
            "loss [0.000210062466096133]\n",
            "val_loss [0.13819026947021484]\n",
            "Epoch 211/1000...\n",
            "loss [0.00018296976713463663]\n",
            "val_loss [0.14292296767234802]\n",
            "Epoch 212/1000...\n",
            "loss [0.0002503886765334755]\n",
            "val_loss [0.15087729692459106]\n",
            "Epoch 213/1000...\n",
            "loss [0.00012808291427791118]\n",
            "val_loss [0.12744787335395813]\n",
            "Epoch 214/1000...\n",
            "loss [0.0001649824809283018]\n",
            "val_loss [0.16920407116413116]\n",
            "Epoch 215/1000...\n",
            "loss [0.00016355406073853372]\n",
            "val_loss [0.10357378423213959]\n",
            "Epoch 216/1000...\n",
            "loss [0.0002083811133634299]\n",
            "val_loss [0.11477356404066086]\n",
            "Epoch 217/1000...\n",
            "loss [9.939973801374436e-05]\n",
            "val_loss [0.16586390137672424]\n",
            "Epoch 218/1000...\n",
            "loss [0.00016501746163703502]\n",
            "val_loss [0.16374823451042175]\n",
            "Epoch 219/1000...\n",
            "loss [9.384389268234372e-05]\n",
            "val_loss [0.0846744179725647]\n",
            "Epoch 220/1000...\n",
            "loss [0.00016974327177740633]\n",
            "val_loss [0.20762920379638672]\n",
            "Epoch 221/1000...\n",
            "loss [0.0002445391360670328]\n",
            "val_loss [0.12075044214725494]\n",
            "Epoch 222/1000...\n",
            "loss [0.0001467861607670784]\n",
            "val_loss [0.16698062419891357]\n",
            "Epoch 223/1000...\n",
            "loss [0.00022284993343055248]\n",
            "val_loss [0.23156894743442535]\n",
            "Epoch 224/1000...\n",
            "loss [0.0002016478208824992]\n",
            "val_loss [0.14631998538970947]\n",
            "Epoch 225/1000...\n",
            "loss [0.0001835578386671841]\n",
            "val_loss [0.18722334504127502]\n",
            "Epoch 226/1000...\n",
            "loss [6.527787446975708e-05]\n",
            "val_loss [0.1436944305896759]\n",
            "Epoch 227/1000...\n",
            "loss [0.00021652131294831633]\n",
            "val_loss [0.13476034998893738]\n",
            "Epoch 228/1000...\n",
            "loss [0.00013155346014536917]\n",
            "val_loss [0.16025137901306152]\n",
            "Epoch 229/1000...\n",
            "loss [0.0002554540846031159]\n",
            "val_loss [0.14592677354812622]\n",
            "Epoch 230/1000...\n",
            "loss [0.0001943527057301253]\n",
            "val_loss [0.06917735189199448]\n",
            "Epoch 231/1000...\n",
            "loss [0.0001273412073496729]\n",
            "val_loss [0.11277172714471817]\n",
            "Epoch 232/1000...\n",
            "loss [0.00014612948312424124]\n",
            "val_loss [0.15191015601158142]\n",
            "Epoch 233/1000...\n",
            "loss [0.00012347193947061897]\n",
            "val_loss [0.22246362268924713]\n",
            "Epoch 234/1000...\n",
            "loss [0.0001980966820847243]\n",
            "val_loss [0.1215682178735733]\n",
            "Epoch 235/1000...\n",
            "loss [0.00023436709120869636]\n",
            "val_loss [0.09328439086675644]\n",
            "Epoch 236/1000...\n",
            "loss [0.0001384994932450354]\n",
            "val_loss [0.1517900824546814]\n",
            "Epoch 237/1000...\n",
            "loss [0.00013137093652039767]\n",
            "val_loss [0.10428116470575333]\n",
            "Epoch 238/1000...\n",
            "loss [0.00015915835695341229]\n",
            "val_loss [0.1485154777765274]\n",
            "Epoch 239/1000...\n",
            "loss [0.0001380318128503859]\n",
            "val_loss [0.12132503092288971]\n",
            "Epoch 240/1000...\n",
            "loss [9.209190309047699e-05]\n",
            "val_loss [0.12818893790245056]\n",
            "Epoch 241/1000...\n",
            "loss [0.00019123654067516326]\n",
            "val_loss [0.14741747081279755]\n",
            "Epoch 242/1000...\n",
            "loss [0.0001603278019465506]\n",
            "val_loss [0.14604905247688293]\n",
            "Epoch 243/1000...\n",
            "loss [0.00011930529214441776]\n",
            "val_loss [0.13076308369636536]\n",
            "Epoch 244/1000...\n",
            "loss [0.0001691146979574114]\n",
            "val_loss [0.09560331702232361]\n",
            "Epoch 245/1000...\n",
            "loss [0.00026950427424162626]\n",
            "val_loss [0.1318386048078537]\n",
            "Epoch 246/1000...\n",
            "loss [0.00020822914224117995]\n",
            "val_loss [0.09784914553165436]\n",
            "Epoch 247/1000...\n",
            "loss [0.00015850277058780194]\n",
            "val_loss [0.09705051779747009]\n",
            "Epoch 248/1000...\n",
            "loss [0.00017191116511821748]\n",
            "val_loss [0.12819543480873108]\n",
            "Epoch 249/1000...\n",
            "loss [0.00013137166853994132]\n",
            "val_loss [0.19112619757652283]\n",
            "Epoch 250/1000...\n",
            "loss [0.00013940395531244576]\n",
            "val_loss [0.11556319892406464]\n",
            "Epoch 251/1000...\n",
            "loss [0.0001402575159445405]\n",
            "val_loss [0.16887223720550537]\n",
            "Epoch 252/1000...\n",
            "loss [0.0002048968425951898]\n",
            "val_loss [0.06795396655797958]\n",
            "Epoch 253/1000...\n",
            "loss [7.667686161585152e-05]\n",
            "val_loss [0.10961651802062988]\n",
            "Epoch 254/1000...\n",
            "loss [0.00015720403240993618]\n",
            "val_loss [0.09758239984512329]\n",
            "Epoch 255/1000...\n",
            "loss [0.00010279598087072372]\n",
            "val_loss [0.12099993973970413]\n",
            "Epoch 256/1000...\n",
            "loss [0.00022007231740280985]\n",
            "val_loss [0.1231122836470604]\n",
            "Epoch 257/1000...\n",
            "loss [0.0001919884099625051]\n",
            "val_loss [0.11752763390541077]\n",
            "Epoch 258/1000...\n",
            "loss [9.680103301070631e-05]\n",
            "val_loss [0.15681831538677216]\n",
            "Epoch 259/1000...\n",
            "loss [0.00013987553818151354]\n",
            "val_loss [0.13209344446659088]\n",
            "Epoch 260/1000...\n",
            "loss [0.00021147873206064105]\n",
            "val_loss [0.13391542434692383]\n",
            "Epoch 261/1000...\n",
            "loss [9.639244270510972e-05]\n",
            "val_loss [0.10699208080768585]\n",
            "Epoch 262/1000...\n",
            "loss [0.00012544615380465985]\n",
            "val_loss [0.21888887882232666]\n",
            "Epoch 263/1000...\n",
            "loss [0.00012124681123532354]\n",
            "val_loss [0.13518913090229034]\n",
            "Epoch 264/1000...\n",
            "loss [0.00021964922570623458]\n",
            "val_loss [0.10269105434417725]\n",
            "Epoch 265/1000...\n",
            "loss [9.17356163263321e-05]\n",
            "val_loss [0.08116207271814346]\n",
            "Epoch 266/1000...\n",
            "loss [0.00020149894361384213]\n",
            "val_loss [0.14523251354694366]\n",
            "Epoch 267/1000...\n",
            "loss [0.00012224739789962769]\n",
            "val_loss [0.09820772707462311]\n",
            "Epoch 268/1000...\n",
            "loss [9.870639257133007e-05]\n",
            "val_loss [0.08112934976816177]\n",
            "Epoch 269/1000...\n",
            "loss [0.00014023202285170556]\n",
            "val_loss [0.06314495950937271]\n",
            "Epoch 270/1000...\n",
            "loss [9.94614139199257e-05]\n",
            "val_loss [0.10062214732170105]\n",
            "Epoch 271/1000...\n",
            "loss [0.00010040449094958603]\n",
            "val_loss [0.12055724114179611]\n",
            "Epoch 272/1000...\n",
            "loss [0.0001498925327323377]\n",
            "val_loss [0.11531204730272293]\n",
            "Epoch 273/1000...\n",
            "loss [0.00011164921522140503]\n",
            "val_loss [0.09456994384527206]\n",
            "Epoch 274/1000...\n",
            "loss [0.00010497708525508642]\n",
            "val_loss [0.12950977683067322]\n",
            "Epoch 275/1000...\n",
            "loss [0.00015317442547529937]\n",
            "val_loss [0.1550964117050171]\n",
            "Epoch 276/1000...\n",
            "loss [0.00014414640376344322]\n",
            "val_loss [0.11789333820343018]\n",
            "Epoch 277/1000...\n",
            "loss [0.0001294145577121526]\n",
            "val_loss [0.14952601492404938]\n",
            "Epoch 278/1000...\n",
            "loss [9.976594080217182e-05]\n",
            "val_loss [0.19325855374336243]\n",
            "Epoch 279/1000...\n",
            "loss [0.00014226582110859454]\n",
            "val_loss [0.18088467419147491]\n",
            "Epoch 280/1000...\n",
            "loss [0.00013289709948003292]\n",
            "val_loss [0.1955554485321045]\n",
            "Epoch 281/1000...\n",
            "loss [0.00025573095493018627]\n",
            "val_loss [0.13636444509029388]\n",
            "Epoch 282/1000...\n",
            "loss [0.00011368452594615519]\n",
            "val_loss [0.1994582861661911]\n",
            "Epoch 283/1000...\n",
            "loss [0.0001266808584332466]\n",
            "val_loss [0.09760527312755585]\n",
            "Epoch 284/1000...\n",
            "loss [0.0001846051993779838]\n",
            "val_loss [0.16285017132759094]\n",
            "Epoch 285/1000...\n",
            "loss [0.00016154166543856264]\n",
            "val_loss [0.09854688495397568]\n",
            "Epoch 286/1000...\n",
            "loss [0.00011431765742599964]\n",
            "val_loss [0.06499984860420227]\n",
            "Epoch 287/1000...\n",
            "loss [5.4119338747113945e-05]\n",
            "val_loss [0.25569310784339905]\n",
            "Epoch 288/1000...\n",
            "loss [0.0001157553601078689]\n",
            "val_loss [0.19921070337295532]\n",
            "Epoch 289/1000...\n",
            "loss [0.00016400187369436026]\n",
            "val_loss [0.07443848252296448]\n",
            "Epoch 290/1000...\n",
            "loss [0.0001073226062580943]\n",
            "val_loss [0.19701212644577026]\n",
            "Epoch 291/1000...\n",
            "loss [0.0001503194305114448]\n",
            "val_loss [0.19715656340122223]\n",
            "Epoch 292/1000...\n",
            "loss [0.00016391622554510831]\n",
            "val_loss [0.14388436079025269]\n",
            "Epoch 293/1000...\n",
            "loss [0.00015198130719363688]\n",
            "val_loss [0.11515948176383972]\n",
            "Epoch 294/1000...\n",
            "loss [7.778373500332236e-05]\n",
            "val_loss [0.10408221185207367]\n",
            "Epoch 295/1000...\n",
            "loss [0.0001503568640910089]\n",
            "val_loss [0.214004248380661]\n",
            "Epoch 296/1000...\n",
            "loss [0.00020106444624252618]\n",
            "val_loss [0.0759643018245697]\n",
            "Epoch 297/1000...\n",
            "loss [0.00011335199279710651]\n",
            "val_loss [0.14555667340755463]\n",
            "Epoch 298/1000...\n",
            "loss [8.03376603871584e-05]\n",
            "val_loss [0.09595760703086853]\n",
            "Epoch 299/1000...\n",
            "loss [0.00015788336843252182]\n",
            "val_loss [0.1558595448732376]\n",
            "Epoch 300/1000...\n",
            "loss [0.0001306323828175664]\n",
            "val_loss [0.15000629425048828]\n",
            "Epoch 301/1000...\n",
            "loss [8.478447375819087e-05]\n",
            "val_loss [0.20881213247776031]\n",
            "Epoch 302/1000...\n",
            "loss [0.00019494981737807392]\n",
            "val_loss [0.14480149745941162]\n",
            "Epoch 303/1000...\n",
            "loss [0.00013267740653827786]\n",
            "val_loss [0.14536866545677185]\n",
            "Epoch 304/1000...\n",
            "loss [0.0001275794804096222]\n",
            "val_loss [0.10435359179973602]\n",
            "Epoch 305/1000...\n",
            "loss [0.00016071305586956442]\n",
            "val_loss [0.09737993031740189]\n",
            "Epoch 306/1000...\n",
            "loss [9.944251435808838e-05]\n",
            "val_loss [0.17440171539783478]\n",
            "Epoch 307/1000...\n",
            "loss [0.00020925192721188069]\n",
            "val_loss [0.12759551405906677]\n",
            "Epoch 308/1000...\n",
            "loss [0.0001120767961256206]\n",
            "val_loss [0.147773876786232]\n",
            "Epoch 309/1000...\n",
            "loss [0.00010322182369418443]\n",
            "val_loss [0.10438434779644012]\n",
            "Epoch 310/1000...\n",
            "loss [7.691071648150682e-05]\n",
            "val_loss [0.11765412986278534]\n",
            "Epoch 311/1000...\n",
            "loss [0.00011551972012966871]\n",
            "val_loss [0.1624680459499359]\n",
            "Epoch 312/1000...\n",
            "loss [0.0001575629934668541]\n",
            "val_loss [0.18343062698841095]\n",
            "Epoch 313/1000...\n",
            "loss [0.00010176732507534325]\n",
            "val_loss [0.1018901914358139]\n",
            "Epoch 314/1000...\n",
            "loss [7.006517797708511e-05]\n",
            "val_loss [0.09683514386415482]\n",
            "Epoch 315/1000...\n",
            "loss [0.00013560637459158898]\n",
            "val_loss [0.13473019003868103]\n",
            "Epoch 316/1000...\n",
            "loss [7.367281056940555e-05]\n",
            "val_loss [0.14645171165466309]\n",
            "Epoch 317/1000...\n",
            "loss [8.502249815501272e-05]\n",
            "val_loss [0.14413787424564362]\n",
            "Epoch 318/1000...\n",
            "loss [7.956615276634693e-05]\n",
            "val_loss [0.14149025082588196]\n",
            "Epoch 319/1000...\n",
            "loss [0.00010639017866924405]\n",
            "val_loss [0.20119786262512207]\n",
            "Epoch 320/1000...\n",
            "loss [9.99901038594544e-05]\n",
            "val_loss [0.10904082655906677]\n",
            "Epoch 321/1000...\n",
            "loss [0.00012328277062624693]\n",
            "val_loss [0.1223953366279602]\n",
            "Epoch 322/1000...\n",
            "loss [0.0001729955216869712]\n",
            "val_loss [0.0770067498087883]\n",
            "Epoch 323/1000...\n",
            "loss [6.89229799900204e-05]\n",
            "val_loss [0.22320736944675446]\n",
            "Epoch 324/1000...\n",
            "loss [0.00012444836925715208]\n",
            "val_loss [0.09191057831048965]\n",
            "Epoch 325/1000...\n",
            "loss [9.339392860420048e-05]\n",
            "val_loss [0.1308872550725937]\n",
            "Epoch 326/1000...\n",
            "loss [0.00017712615430355073]\n",
            "val_loss [0.19484978914260864]\n",
            "Epoch 327/1000...\n",
            "loss [0.00012496879301033913]\n",
            "val_loss [0.19645586609840393]\n",
            "Epoch 328/1000...\n",
            "loss [0.00015063228830695152]\n",
            "val_loss [0.1462581604719162]\n",
            "Epoch 329/1000...\n",
            "loss [0.00012210716120898723]\n",
            "val_loss [0.15099729597568512]\n",
            "Epoch 330/1000...\n",
            "loss [0.00015762213338166477]\n",
            "val_loss [0.15354390442371368]\n",
            "Epoch 331/1000...\n",
            "loss [0.00012076171021908522]\n",
            "val_loss [0.09451422840356827]\n",
            "Epoch 332/1000...\n",
            "loss [0.00016285651433281602]\n",
            "val_loss [0.15254628658294678]\n",
            "Epoch 333/1000...\n",
            "loss [7.650957349687814e-05]\n",
            "val_loss [0.165832057595253]\n",
            "Epoch 334/1000...\n",
            "loss [7.00625863391906e-05]\n",
            "val_loss [0.16330324113368988]\n",
            "Epoch 335/1000...\n",
            "loss [0.000156606919830665]\n",
            "val_loss [0.09658273309469223]\n",
            "Epoch 336/1000...\n",
            "loss [9.017938864417375e-05]\n",
            "val_loss [0.11699581146240234]\n",
            "Epoch 337/1000...\n",
            "loss [0.000133220566669479]\n",
            "val_loss [0.12262367457151413]\n",
            "Epoch 338/1000...\n",
            "loss [4.702525353059173e-05]\n",
            "val_loss [0.15416891872882843]\n",
            "Epoch 339/1000...\n",
            "loss [0.00016801853757351636]\n",
            "val_loss [0.1272028088569641]\n",
            "Epoch 340/1000...\n",
            "loss [8.822675282135605e-05]\n",
            "val_loss [0.10451668500900269]\n",
            "Epoch 341/1000...\n",
            "loss [0.00012729471921920775]\n",
            "val_loss [0.1307918280363083]\n",
            "Epoch 342/1000...\n",
            "loss [0.0001651213257573545]\n",
            "val_loss [0.0795428454875946]\n",
            "Epoch 343/1000...\n",
            "loss [0.00012174645718187094]\n",
            "val_loss [0.10270608216524124]\n",
            "Epoch 344/1000...\n",
            "loss [0.00012995588779449462]\n",
            "val_loss [0.08141900599002838]\n",
            "Epoch 345/1000...\n",
            "loss [0.00016472755325958133]\n",
            "val_loss [0.08629559725522995]\n",
            "Epoch 346/1000...\n",
            "loss [0.00013436556723900138]\n",
            "val_loss [0.06634555011987686]\n",
            "Epoch 347/1000...\n",
            "loss [9.794103307649493e-05]\n",
            "val_loss [0.10293550789356232]\n",
            "Epoch 348/1000...\n",
            "loss [4.037652770057321e-05]\n",
            "val_loss [0.037460923194885254]\n",
            "Epoch 349/1000...\n",
            "loss [6.308480817824603e-05]\n",
            "val_loss [0.18818312883377075]\n",
            "Epoch 350/1000...\n",
            "loss [0.00012717273109592498]\n",
            "val_loss [0.10431425273418427]\n",
            "Epoch 351/1000...\n",
            "loss [0.00012096408894285559]\n",
            "val_loss [0.08173365890979767]\n",
            "Epoch 352/1000...\n",
            "loss [0.0001225253522861749]\n",
            "val_loss [0.037832096219062805]\n",
            "Epoch 353/1000...\n",
            "loss [0.0001496950483415276]\n",
            "val_loss [0.12538501620292664]\n",
            "Epoch 354/1000...\n",
            "loss [9.880770021118224e-05]\n",
            "val_loss [0.1176692396402359]\n",
            "Epoch 355/1000...\n",
            "loss [7.95524453278631e-05]\n",
            "val_loss [0.12942053377628326]\n",
            "Epoch 356/1000...\n",
            "loss [0.0001213321858085692]\n",
            "val_loss [0.15143424272537231]\n",
            "Epoch 357/1000...\n",
            "loss [0.00011222002888098359]\n",
            "val_loss [0.11184315383434296]\n",
            "Epoch 358/1000...\n",
            "loss [9.328727843239903e-05]\n",
            "val_loss [0.05680804327130318]\n",
            "Epoch 359/1000...\n",
            "loss [0.0001382400430738926]\n",
            "val_loss [0.09630522131919861]\n",
            "Epoch 360/1000...\n",
            "loss [0.00011141846165992319]\n",
            "val_loss [0.1221993938088417]\n",
            "Epoch 361/1000...\n",
            "loss [0.00011223358218558133]\n",
            "val_loss [0.12680664658546448]\n",
            "Epoch 362/1000...\n",
            "loss [0.00010924246604554356]\n",
            "val_loss [0.11592504382133484]\n",
            "Epoch 363/1000...\n",
            "loss [0.00011450725933536887]\n",
            "val_loss [0.1492035686969757]\n",
            "Epoch 364/1000...\n",
            "loss [0.00013318464998155833]\n",
            "val_loss [0.14214777946472168]\n",
            "Epoch 365/1000...\n",
            "loss [0.00014759446796961127]\n",
            "val_loss [0.1533820927143097]\n",
            "Epoch 366/1000...\n",
            "loss [0.00011461427551694214]\n",
            "val_loss [0.16376645863056183]\n",
            "Epoch 367/1000...\n",
            "loss [0.00016875773132778705]\n",
            "val_loss [0.17877008020877838]\n",
            "Epoch 368/1000...\n",
            "loss [0.0001246385525446385]\n",
            "val_loss [0.04290635883808136]\n",
            "Epoch 369/1000...\n",
            "loss [9.03867520391941e-05]\n",
            "val_loss [0.10542969405651093]\n",
            "Epoch 370/1000...\n",
            "loss [0.00011509510641917586]\n",
            "val_loss [0.14608530700206757]\n",
            "Epoch 371/1000...\n",
            "loss [0.00010836507147178054]\n",
            "val_loss [0.13419243693351746]\n",
            "Epoch 372/1000...\n",
            "loss [0.00013810441084206103]\n",
            "val_loss [0.06088925525546074]\n",
            "Epoch 373/1000...\n",
            "loss [0.00012256112787872552]\n",
            "val_loss [0.15787148475646973]\n",
            "Epoch 374/1000...\n",
            "loss [8.117052540183067e-05]\n",
            "val_loss [0.12666091322898865]\n",
            "Epoch 375/1000...\n",
            "loss [0.00015917505882680417]\n",
            "val_loss [0.10702939331531525]\n",
            "Epoch 376/1000...\n",
            "loss [8.948224969208241e-05]\n",
            "val_loss [0.1454341560602188]\n",
            "Epoch 377/1000...\n",
            "loss [3.9668645011261105e-05]\n",
            "val_loss [0.11362753063440323]\n",
            "Epoch 378/1000...\n",
            "loss [0.00011895334394648671]\n",
            "val_loss [0.08608005195856094]\n",
            "Epoch 379/1000...\n",
            "loss [0.00014767707884311677]\n",
            "val_loss [0.14350613951683044]\n",
            "Epoch 380/1000...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0xLQNlax0ZcD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}