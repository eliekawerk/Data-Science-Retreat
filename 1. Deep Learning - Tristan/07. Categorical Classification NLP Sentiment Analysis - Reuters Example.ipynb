{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garethjones/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/garethjones/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:955: UserWarning: Illegal line #3\n",
      "\t\"\"\"\"\n",
      "\"\n",
      "\tin file \"/Users/garethjones/anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc\"\n",
      "  warnings.warn('Illegal %s' % error_details)\n",
      "/Users/garethjones/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:955: UserWarning: Illegal line #7\n",
      "\t\"\"\"\"\n",
      "\"\n",
      "\tin file \"/Users/garethjones/anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc\"\n",
      "  warnings.warn('Illegal %s' % error_details)\n",
      "\n",
      "Bad key \"Created on Thu May 24 09\" on line 4 in\n",
      "/Users/garethjones/anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"@author\" on line 6 in\n",
      "/Users/garethjones/anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "(train_data,train_labels),(test_data,test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset is shape:  (8982,)\n",
      "Training labels is shape:  (8982,)\n",
      "Testing dataset is shape:  (2246,)\n",
      "Testing labels is shape:  (2246,)\n",
      "The max length of a single sample is  2376\n",
      "The min length of a single sample is  13\n",
      "The avg length of all samples is  146.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3,  4,  3, ..., 25,  3, 25])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Training dataset is shape: \",train_data.shape)\n",
    "print(\"Training labels is shape: \",train_labels.shape)\n",
    "print(\"Testing dataset is shape: \",test_data.shape)\n",
    "print(\"Testing labels is shape: \",test_labels.shape)\n",
    "\n",
    "# find lengths of all the samples\n",
    "x = [len(i) for i in train_data]\n",
    "print(\"The max length of a single sample is \",max(x))\n",
    "print(\"The min length of a single sample is \",min(x))\n",
    "print(\"The avg length of all samples is \",round(np.mean(x)))\n",
    "\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? the farmers home administration the u s agriculture department's farm lending arm could lose about seven billion dlrs in outstanding principal on its severely ? borrowers or about one fourth of its farm loan portfolio the general accounting office gao said in remarks prepared for delivery to the senate agriculture committee brian crowley senior associate director of gao also said that a preliminary analysis of proposed changes in ? financial eligibility standards indicated as many as one half of ? borrowers who received new loans from the agency in 1986 would be ? under the proposed system the agency has proposed evaluating ? credit using a variety of financial ratios instead of relying solely on ? ability senate agriculture committee chairman patrick leahy d vt ? the proposed eligibility changes telling ? administrator ? clark at a hearing that they would mark a dramatic shift in the agency's purpose away from being farmers' lender of last resort toward becoming a big city bank but clark defended the new regulations saying the agency had a responsibility to ? its 70 billion dlr loan portfolio in a ? yet ? manner crowley of gao ? ? arm said the proposed credit ? system attempted to ensure that ? would make loans only to borrowers who had a reasonable change of repaying their debt reuter 3\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "# I want to have a look to see what the data actually is\n",
    "# I need to turn by keys into values using my reverse word index\n",
    "train_data[0]\n",
    "\n",
    "#decoded_train_data1 = []\n",
    "#for i in train_data[0]:\n",
    "#    x = reverse_word_index.get(i-3,'?')\n",
    "#    decoded_train_data1.append(x)\n",
    "#print(decoded_train_data1)\n",
    "\n",
    "# get good at this list enumeration thing!\n",
    "decoded_train_data = [reverse_word_index.get(i-3,'?') for i in train_data[3]]\n",
    "reuters_message = \" \".join(i for i in decoded_train_data)\n",
    "print(reuters_message)\n",
    "\n",
    "# now I want to see how many categories there are for each sample\n",
    "print(max(train_labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]), array([  55,  432,   74, 3159, 1949,   17,   48,   16,  139,  101,  124,\n",
      "        390,   49,  172,   26,   20,  444,   39,   66,  549,  269,  100,\n",
      "         15,   41,   62,   92,   24,   15,   48,   19,   45,   39,   32,\n",
      "         11,   50,   10,   49,   19,   19,   24,   36,   30,   13,   21,\n",
      "         12,   18]))\n"
     ]
    }
   ],
   "source": [
    "x = np.array(train_labels)\n",
    "unique, counts = np.unique(x, return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30979\n",
      "(8982, 10000)\n",
      "(2246, 10000)\n",
      "Original output shape:  (8982,)\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "print(len(word_index))\n",
    "\n",
    "# create the reverse of the word_index so I can match to the original dataset\n",
    "reverse_word_index = dict([(keys,values) for (values,keys) in word_index.items()])\n",
    "\n",
    "# now I need to encode the samples in my dataset by vectorising each one. I can create a function to do this\n",
    "# this creates a 2D numpy array of 1s and 0s showing each word in the sample corresponding to each word index\n",
    "def vectorise_sequences(sequence,dimension=10000):\n",
    "    result = np.zeros((len(sequence),dimension))\n",
    "    for i, value in enumerate(sequence):\n",
    "        result[i,value] = 1\n",
    "    return result\n",
    "\n",
    "# pass train and test samples to the function to get my x_train / test data\n",
    "x_train = vectorise_sequences(train_data)\n",
    "x_test = vectorise_sequences(test_data)\n",
    "\n",
    "# be sure about the shape of the data that we're dealing with\n",
    "# the output is 10000 long because we said only use the first 10,000 words when we imported the dataset\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# the model was failing because I was showing the it an output of size one, but it was expecting it to be 46 (one-hot encoded)\n",
    "print('Original output shape: ',y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 16)                160016    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 45)                765       \n",
      "=================================================================\n",
      "Total params: 161,053\n",
      "Trainable params: 161,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(16,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers,losses,metrics\n",
    "#model.compile(optimizer=optimizers.RMSprop(),\n",
    "#             loss=losses.binary_crossentropy(),\n",
    "#             metrics=[metrics.accuracy()])\n",
    "model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_47 to have shape (45,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-2d1660ee8971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    135\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_47 to have shape (45,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=5,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
