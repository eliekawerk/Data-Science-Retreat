{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding (Using Matrix Indexing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y = np.r_[1,7,0,5,0]\n",
    "Kmax = 10 # number of categories\n",
    "\n",
    "# this is basic, using a for-loop\n",
    "def one_hot_encode1(y,Kmax):\n",
    "    n = y.shape[0] # number of rows\n",
    "    r = np.zeros((n,Kmax)) # create matrix of zeros\n",
    "    for i in range(n): # for the number of categories\n",
    "        r[i,y[i]] = 1 # select the first row of zeros matrix, select the column corresponding to value of input vector\n",
    "    return r\n",
    "\n",
    "# this is next level without for-loop, just by using matrix selection\n",
    "def one_hot_encode2(y,Kmax):\n",
    "    n = y.shape[0] # number of rows\n",
    "    r = np.zeros((n,Kmax)) # create matrix of zeros\n",
    "    r[np.arange(n),y] = 1 # this then does element-wise selection\n",
    "    return r\n",
    "\n",
    "# now there's an even more elegant way of doing this\n",
    "# we can create an identity matrix and then select the rows of the identity matrix we want by the row of the categories\n",
    "def one_hot_encode3(y,Kmax):\n",
    "    r = np.eye(Kmax)[y,:]\n",
    "    return r\n",
    "\n",
    "# all the results are the same!\n",
    "print(one_hot_encoding1(y,Kmax))\n",
    "print(one_hot_encoding2(y,Kmax))\n",
    "print(one_hot_encoding3(y,Kmax))\n",
    "\n",
    "# we can decode this in one line\n",
    "def one_hot_decode(Y):\n",
    "    return np.argmax(Y,axis=1) # Y.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-entropy grad descent and stochastic gradient descent from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-117-15bba3d257a8>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/garethjones/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/garethjones/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 26421880 bytes.\n",
      "WARNING:tensorflow:From /Users/garethjones/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 29515 bytes.\n",
      "WARNING:tensorflow:From /Users/garethjones/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 4422102 bytes.\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 5148 bytes.\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/garethjones/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# We're going to do some programming but using machine learning\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/fashion', \n",
    "source_url='http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data.train.images\n",
    "X_test = data.test.images\n",
    "Y_train = data.train.labels\n",
    "Y_test = data.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(10000, 784)\n",
      "(55000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# the shapes denote these are images that are 28x28\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 labels are: [4 0 7 9 9 9 4 4 3 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c442b0f60>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('The first 10 labels are: '+str(Y_train[:10]))\n",
    "plt.imshow(X_train[0,:].reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.  0.  0.  0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "# Let's define the softmax probability calcuator\n",
    "\n",
    "# this is the output from our matrix multiplication of weights and biases\n",
    "y = np.r_[-7,24,17,-10,100,100]\n",
    "\n",
    "# we need to add a row of 1s to our matrix because this allows us to unhinge the decision plane from 0\n",
    "X_train2 = np.insert(X_train,0,1,axis=1)\n",
    "X_test2 = np.insert(X_test,0,1,axis=1)\n",
    "\n",
    "def softmax(y):\n",
    "    # add axis = 1\n",
    "    result = np.exp(y) / np.sum(np.exp(y),axis=1).reshape(-1,1)\n",
    "    return result\n",
    "\n",
    "print(np.round(softmax(y),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.94939667e-047 4.51969280e-048 3.38560511e-050 ... 6.62527272e-047\n",
      "  5.44882685e-050 2.33264665e-045]\n",
      " [9.55107389e-093 4.86150432e-094 1.70833424e-095 ... 7.90854116e-092\n",
      "  2.27663094e-093 7.86169035e-089]\n",
      " [4.94117154e-099 9.52898403e-101 6.75832520e-102 ... 9.43154222e-099\n",
      "  3.42354357e-101 7.39986783e-096]\n",
      " ...\n",
      " [1.29928023e-076 2.96263025e-076 1.97230134e-080 ... 1.22581273e-075\n",
      "  5.96863049e-078 8.69115861e-072]\n",
      " [7.49667205e-101 1.48869765e-101 1.18289264e-102 ... 4.03208165e-099\n",
      "  3.50333123e-101 2.04188481e-096]\n",
      " [1.51015960e-114 8.53782920e-116 4.09163869e-116 ... 5.48636258e-113\n",
      "  3.23354236e-115 1.39065518e-111]]\n",
      "(55000, 10)\n",
      "[9 9 9 ... 9 9 9]\n",
      "[4 0 7 ... 3 0 5]\n",
      "[False False False ... False False False]\n",
      "Accuracy = 0.091\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "# create weight matrix\n",
    "W = np.random.rand(785,10)\n",
    "Y = softmax(X_train2 @ W) \n",
    "# we see that Y is a matrix that's number of samples long, number of categories wide\n",
    "print(Y)\n",
    "print(Y.shape)\n",
    "\n",
    "# we can now decode these probabilities into likely categories\n",
    "print(one_hot_decode(Y))\n",
    "# these are the real values\n",
    "print(Y_train)\n",
    "\n",
    "# we can check the accuracy of our classifier\n",
    "# this creates a boolean matrix, that we can then find proportion of Trues!\n",
    "acc = np.mean(one_hot_decode(Y)==Y_train)\n",
    "print(\"Accuracy = \"+str(np.round(acc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-entropy is a way of seeing how close our predictions are from the real labels\n",
    "# it's defined as taking the log of every prediction\n",
    "\n",
    "Y_train2 = one_hot_encode3(Y_train,10)\n",
    "Y_test2 = one_hot_encode3(Y_test,10)\n",
    "\n",
    "def crossentropy(W, X_train2, Y_train2):\n",
    "    Y_pred = softmax(X_train2 @ W)\n",
    "    return -np.sum(Y_train2 * np.log(Y_pred)) / X_train2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy_grad(W, X_train2, Y_train2):\n",
    "    Y_pred = softmax(X_train2 @ W)\n",
    "    return -(X_train2.T @ (Y_train2 - Y_pred) / X_train2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    " def accuracy(W, X_train, Y_train):\n",
    "    Y_pred = softmax(X_train @ W)\n",
    "    return np.mean(one_hot_decode(Y_pred) == one_hot_decode(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "w = np.random.rand(785,10)\n",
    "maxiter = 10\n",
    "eta = 0.1 # I think this is learning rate?\n",
    "for i in range(maxiter):\n",
    "    w = w - eta*crossentropy_grad(W,X_train2,Y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garethjones/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in exp\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/garethjones/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: TRAIN: accuracy=0.100 cross_entropy=   nan  TEST:  accuracy=0.100 cross_entropy=   nan\n",
      "200: TRAIN: accuracy=0.101 cross_entropy=   nan  TEST:  accuracy=0.100 cross_entropy=   nan\n",
      "300: TRAIN: accuracy=0.101 cross_entropy=   nan  TEST:  accuracy=0.100 cross_entropy=   nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garethjones/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n",
      "/Users/garethjones/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in multiply\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400: TRAIN: accuracy=0.101 cross_entropy=   nan  TEST:  accuracy=0.100 cross_entropy=   nan\n",
      "500: TRAIN: accuracy=0.101 cross_entropy=   nan  TEST:  accuracy=0.100 cross_entropy=   nan\n",
      "600: TRAIN: accuracy=0.101 cross_entropy=   nan  TEST:  accuracy=0.100 cross_entropy=   nan\n",
      "700: TRAIN: accuracy=0.101 cross_entropy=   nan  TEST:  accuracy=0.100 cross_entropy=   nan\n",
      "800: TRAIN: accuracy=0.101 cross_entropy=   nan  TEST:  accuracy=0.100 cross_entropy=   nan\n",
      "900: TRAIN: accuracy=0.101 cross_entropy=   nan  TEST:  accuracy=0.100 cross_entropy=   nan\n",
      "1000: TRAIN: accuracy=0.101 cross_entropy=   nan  TEST:  accuracy=0.100 cross_entropy=   nan\n"
     ]
    }
   ],
   "source": [
    "# to do stochastic cross-entropy, we just choose a random row from our training dataset to do the calculation\n",
    "# because we're doing this on a single number, we need to increase the number of iterations we're doing!\n",
    "for i in range(maxiter):\n",
    "    k = np.r_[np.random.choice(np.arange(X_train.shape[0]), 550)]\n",
    "    W = W - eta*crossentropy_grad(W, X_train2[k,:], Y_train2[k,:])\n",
    "    \n",
    "    if i % 100 == 99:\n",
    "        print(\"%3d: TRAIN: accuracy=%.3f cross_entropy=%6.2f  TEST:  accuracy=%.3f cross_entropy=%6.2f\" %\n",
    "          (i+1,\n",
    "              accuracy(W, X_train2, Y_train2),\n",
    "               crossentropy(W, X_train2, Y_train2),\n",
    "               accuracy(W, X_test2, Y_test2),\n",
    "               crossentropy(W, X_test2, Y_test2)\n",
    "          ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Softmax_4:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"truediv_3:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'GradientDescent_2' type=NoOp>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's implement a neural network and our cross entropy in tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# this cell sets everything up for us \n",
    "\n",
    "# we do some variable declarations\n",
    "w = tf.Variable(tf.random_normal((785,10)))\n",
    "\n",
    "# we need a placeholder for our input data\n",
    "x = tf.placeholder(tf.float32, [None,785]) # None means some number of rows, like -1 in our matrix indexing\n",
    "y = tf.placeholder(tf.float32, [None,10]) \n",
    "\n",
    "# to do our predictions as before, we do a softmax of a matrix multiplication\n",
    "# this is preparing our matrix of predictions\n",
    "y_pred = tf.nn.softmax(tf.matmul(x,w)) # matmul is equivalent to @\n",
    "print(y_pred) # we have shape (?,10) becausew e don't know how many rows we're going to input yet, given our None claus\n",
    "\n",
    "# tensorflow is very sensitive to data types. So we need to ensure division is done by same data types\n",
    "# so we cast our shape int to a float\n",
    "cross_entropy = -tf.reduce_sum(y*tf.log(y_pred)) / tf.cast(tf.shape(x),tf.float32)[0]\n",
    "print(cross_entropy)\n",
    "\n",
    "# now we can computer the gradient of the cross-entropy function\n",
    "eta = 0.1 # this is learning rate\n",
    "cross_entropy_grad_step = tf.train.GradientDescentOptimizer(eta).minimize(cross_entropy)\n",
    "cross_entropy_grad_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_entropy=nan\n"
     ]
    }
   ],
   "source": [
    "# this cell now initialises our calculations\n",
    "\n",
    "np.random.seed(12345)\n",
    "W = np.random.randn(785,10)\n",
    "maxiter = 1000\n",
    "eta  = 0.1\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(maxiter):\n",
    "    k = np.r_[np.random.choice(np.arange(X_train.shape[0]), 550)]\n",
    "    #W = W - eta*crossentropy_grad(W, X_train2[k,:], Y_train2[k,:])\n",
    "    \n",
    "    sess.run(cross_entropy_grad_step, feed_dict={\n",
    "            x: X_train2[k,:],\n",
    "            y: Y_train2[k,:]\n",
    "    })\n",
    "    \n",
    "print(\"cross_entropy=%f\" % sess.run(cross_entropy, feed_dict={\n",
    "        x: X_train2, y: Y_train2\n",
    "}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
